{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  legitimate       0.70      0.89      0.79    105528\n",
      "         dos       0.94      0.94      0.94    105528\n",
      "     slowite       1.00      0.44      0.61    105528\n",
      "   malformed       0.34      0.39      0.36    105528\n",
      "  bruteforce       0.81      0.90      0.85    105528\n",
      "       flood       0.94      0.98      0.96    105528\n",
      "\n",
      "    accuracy                           0.76    633168\n",
      "   macro avg       0.79      0.76      0.75    633168\n",
      "weighted avg       0.79      0.76      0.75    633168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib  # for loading .pkl model files\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the pre-trained LightGBM model\n",
    "model = joblib.load('best_re-trained_lgb.pkl')\n",
    "\n",
    "# Load your dataset with ',' as the separator\n",
    "file_path = 'combined_captured_data_MQTT_final.csv'  # Update this with your dataset path\n",
    "df = pd.read_csv(file_path, sep=',')\n",
    "\n",
    "# Adjust the feature list to match the actual column names in your dataset\n",
    "expected_features = [\n",
    "    'tcp_flags', 'tcp_time_delta', 'tcp_len', 'mqtt_conack_flags', \n",
    "    'mqtt_conflag_cleansess', 'mqtt_conflags', 'mqtt_dupflag', \n",
    "    'mqtt_hdrflags', 'mqtt_kalive', 'mqtt_msg', 'mqtt_qos'\n",
    "]\n",
    "\n",
    "# Check if the expected features exist in the dataset\n",
    "if all(feature in df.columns for feature in expected_features):\n",
    "    # Separate features (X) and target (y)\n",
    "    X = df[expected_features]  # Use only the specified features\n",
    "    y_true = df['target']  # The target column is 'target'\n",
    "\n",
    "    # Scale the features using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Mapping for label encoding and decoding\n",
    "    label_mapping = {\n",
    "        \"legitimate\": 0,\n",
    "        \"dos\": 1,\n",
    "        \"slowite\": 2,\n",
    "        \"malformed\": 3,\n",
    "        \"bruteforce\": 4,\n",
    "        \"flood\": 5\n",
    "    }\n",
    "\n",
    "    # Reverse mapping to convert predictions back to string labels\n",
    "    reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "    # Convert true labels to string format using reverse mapping\n",
    "    y_true = y_true.map(reverse_label_mapping)\n",
    "\n",
    "    # Make predictions using the loaded model\n",
    "    y_pred_numeric = model.predict(X_scaled)\n",
    "\n",
    "    # Convert numeric predictions back to string labels\n",
    "    y_pred = [reverse_label_mapping[pred] for pred in y_pred_numeric]\n",
    "\n",
    "    # Generate the classification report\n",
    "    report = classification_report(y_true, y_pred, target_names=label_mapping.keys(), zero_division=1)\n",
    "\n",
    "    # Print the classification report\n",
    "    print(report)\n",
    "else:\n",
    "    missing_features = [feature for feature in expected_features if feature not in df.columns]\n",
    "    print(f\"The following required features are missing from your dataset: {missing_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  legitimate       0.61      0.49      0.54    105528\n",
      "         dos       0.24      0.53      0.33    105528\n",
      "     slowite       0.20      0.02      0.03    105528\n",
      "   malformed       0.13      0.33      0.19    105528\n",
      "  bruteforce       1.00      0.00      0.00    105528\n",
      "       flood       0.05      0.03      0.03    105528\n",
      "\n",
      "    accuracy                           0.23    633168\n",
      "   macro avg       0.37      0.23      0.19    633168\n",
      "weighted avg       0.37      0.23      0.19    633168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib  # for loading .pkl model files\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the pre-trained LightGBM model\n",
    "model = joblib.load('best_lgb.pkl')\n",
    "\n",
    "# Load your dataset with ',' as the separator\n",
    "file_path = 'combined_captured_data_MQTT_final.csv'  # Update this with your dataset path\n",
    "df = pd.read_csv(file_path, sep=',')\n",
    "\n",
    "# Adjust the feature list to match the actual column names in your dataset\n",
    "expected_features = [\n",
    "    'tcp_flags', 'tcp_time_delta', 'tcp_len', 'mqtt_conack_flags', \n",
    "    'mqtt_conflag_cleansess', 'mqtt_conflags', 'mqtt_dupflag', \n",
    "    'mqtt_hdrflags', 'mqtt_kalive', 'mqtt_msg', 'mqtt_qos'\n",
    "]\n",
    "\n",
    "# Check if the expected features exist in the dataset\n",
    "if all(feature in df.columns for feature in expected_features):\n",
    "    # Separate features (X) and target (y)\n",
    "    X = df[expected_features]  # Use only the specified features\n",
    "    y_true = df['target']  # The target column is 'target'\n",
    "\n",
    "    # Scale the features using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Mapping for label encoding and decoding\n",
    "    label_mapping = {\n",
    "        \"legitimate\": 0,\n",
    "        \"dos\": 1,\n",
    "        \"slowite\": 2,\n",
    "        \"malformed\": 3,\n",
    "        \"bruteforce\": 4,\n",
    "        \"flood\": 5\n",
    "    }\n",
    "\n",
    "    # Reverse mapping to convert predictions back to string labels\n",
    "    reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "    # Convert true labels to string format using reverse mapping\n",
    "    y_true = y_true.map(reverse_label_mapping)\n",
    "\n",
    "    # Make predictions using the loaded model\n",
    "    y_pred_numeric = model.predict(X_scaled)\n",
    "\n",
    "    # Convert numeric predictions back to string labels\n",
    "    y_pred = [reverse_label_mapping[pred] for pred in y_pred_numeric]\n",
    "\n",
    "    # Generate the classification report\n",
    "    report = classification_report(y_true, y_pred, target_names=label_mapping.keys(), zero_division=1)\n",
    "\n",
    "    # Print the classification report\n",
    "    print(report)\n",
    "else:\n",
    "    missing_features = [feature for feature in expected_features if feature not in df.columns]\n",
    "    print(f\"The following required features are missing from your dataset: {missing_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
